out <- unlist(e1071::classAgreement(table(obs, pred)))[c("diag", "kappa")]
probs <- data[, cls]
actual <- model.matrix(~ obs - 1)
out2 <- LogLos(actual = actual, pred = probs)
}
out <- c(out, out2)
names(out) <- c("Accuracy", "Kappa", "LogLoss")
if (any(is.nan(out))) out[is.nan(out)] <- NA
out
}
# Create training controls for repeated cross-validation for KNN
knn_control <- trainControl(method = "repeatedcv",
number = 10,
classProbs = TRUE,
summaryFunction = LogLossSummary)
# Create vector of hyper-parameter values to tune over
knn_grid <- expand.grid(k = c(1:20))
# Train KNN model
knn_fit <- train(Made.Donation.in.March.2007 ~ Months.since.Last.Donation + Number.of.Donations + Total.Volume.Donated..c.c.. + Months.since.First.Donation,
data = train,
method = "knn",
metric = "LogLoss",
trControl = knn_control,
tuneGrid = knn_grid,
verbose = TRUE)
# Install and load pacakges
list.of.packages <- c("dplyr", "caret", "e1071")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
library(dplyr)
library(caret)
library(e1071)
# Load data
train <- read.csv("data/BloodDonationTrainingData.csv", header = TRUE, stringsAsFactors = FALSE)
test <- read.csv("data/BloodDonationTestData.csv", header = TRUE, stringsAsFactors = FALSE)
example_submission <- read.csv("data/BloodDonationSubmissionFormat.csv", header = TRUE, stringsAsFactors = FALSE)
# Convert y labels of training data to factor
train$Made.Donation.in.March.2007 <- levels(train$Made.Donation.in.March.2007)
View(train)
train <- read.csv("data/BloodDonationTrainingData.csv", header = TRUE, stringsAsFactors = FALSE)
test <- read.csv("data/BloodDonationTestData.csv", header = TRUE, stringsAsFactors = FALSE)
example_submission <- read.csv("data/BloodDonationSubmissionFormat.csv", header = TRUE, stringsAsFactors = FALSE)
levels(train$Made.Donation.in.March.2007)
View(train)
levels(train$Made.Donation.in.March.2007)
train$Made.Donation.in.March.2007 <- levels(as.factor(train$Made.Donation.in.March.2007))
View(train)
# Create training controls for repeated cross-validation for KNN
knn_control <- trainControl(method = "repeatedcv",
number = 10,
classProbs = TRUE,
summaryFunction = LogLossSummary)
# Create vector of hyper-parameter values to tune over
knn_grid <- expand.grid(k = c(1:20))
# Train KNN model
knn_fit <- train(Made.Donation.in.March.2007 ~ Months.since.Last.Donation + Number.of.Donations + Total.Volume.Donated..c.c.. + Months.since.First.Donation,
data = train,
method = "knn",
metric = "LogLoss",
trControl = knn_control,
tuneGrid = knn_grid,
verbose = TRUE)
train <- read.csv("data/BloodDonationTrainingData.csv", header = TRUE, stringsAsFactors = FALSE)
test <- read.csv("data/BloodDonationTestData.csv", header = TRUE, stringsAsFactors = FALSE)
example_submission <- read.csv("data/BloodDonationSubmissionFormat.csv", header = TRUE, stringsAsFactors = FALSE)
levels(train$Made.Donation.in.March.2007) <- ("yes", "no")
# Load data
train <- read.csv("data/BloodDonationTrainingData.csv", header = TRUE, stringsAsFactors = FALSE)
test <- read.csv("data/BloodDonationTestData.csv", header = TRUE, stringsAsFactors = FALSE)
example_submission <- read.csv("data/BloodDonationSubmissionFormat.csv", header = TRUE, stringsAsFactors = FALSE)
# Convert y labels of training data to factor
levels(train$Made.Donation.in.March.2007) <- make.names(levels(factor(train$Made.Donation.in.March.2007)))
View(train)
levels(train$Made.Donation.in.March.2007) <- make.names(levels(factor(train$Made.Donation.in.March.2007)))
View(train)
# Create training controls for repeated cross-validation for KNN
knn_control <- trainControl(method = "repeatedcv",
number = 10,
classProbs = TRUE,
summaryFunction = twoClassSummary)
# Create vector of hyper-parameter values to tune over
knn_grid <- expand.grid(k = c(1:20))
# Train KNN model
knn_fit <- train(Made.Donation.in.March.2007 ~ Months.since.Last.Donation + Number.of.Donations + Total.Volume.Donated..c.c.. + Months.since.First.Donation,
data = train,
method = "knn",
metric = "ROC",
trControl = knn_control,
tuneGrid = knn_grid,
verbose = TRUE)
# Create training controls for repeated cross-validation for KNN
knn_control <- trainControl(method = "repeatedcv",
number = 10,
classProbs = TRUE,
summaryFunction = twoClassSummary)
# Create vector of hyper-parameter values to tune over
knn_grid <- expand.grid(k = c(1:20))
# Train KNN model
knn_fit <- train(as.factor(Made.Donation.in.March.2007) ~ Months.since.Last.Donation + Number.of.Donations + Total.Volume.Donated..c.c.. + Months.since.First.Donation,
data = train,
method = "knn",
metric = "ROC",
trControl = knn_control,
tuneGrid = knn_grid,
verbose = TRUE)
train$Made.Donation.in.March.2007[train$Made.Donation.in.March.2007 ==1] <- "yes"
train$Made.Donation.in.March.2007[train$Made.Donation.in.March.2007 ==0] <- "no"
train <- read.csv("data/BloodDonationTrainingData.csv", header = TRUE, stringsAsFactors = FALSE)
test <- read.csv("data/BloodDonationTestData.csv", header = TRUE, stringsAsFactors = FALSE)
example_submission <- read.csv("data/BloodDonationSubmissionFormat.csv", header = TRUE, stringsAsFactors = FALSE)
train$Made.Donation.in.March.2007[train$Made.Donation.in.March.2007 ==1] <- "yes"
train$Made.Donation.in.March.2007[train$Made.Donation.in.March.2007 ==0] <- "no"
as.factor(train$Made.Donation.in.March.2007)
# Create training controls for repeated cross-validation for KNN
knn_control <- trainControl(method = "repeatedcv",
number = 10,
classProbs = TRUE,
summaryFunction = twoClassSummary)
# Create vector of hyper-parameter values to tune over
knn_grid <- expand.grid(k = c(1:20))
# Train KNN model
knn_fit <- train(as.factor(Made.Donation.in.March.2007) ~ Months.since.Last.Donation + Number.of.Donations + Total.Volume.Donated..c.c.. + Months.since.First.Donation,
data = train,
method = "knn",
metric = "ROC",
trControl = knn_control,
tuneGrid = knn_grid,
verbose = TRUE)
# Create training controls for repeated cross-validation for KNN
knn_control <- trainControl(method = "repeatedcv",
number = 10,
classProbs = TRUE,
summaryFunction = twoClassSummary)
# Create vector of hyper-parameter values to tune over
knn_grid <- expand.grid(k = c(1:20))
# Train KNN model
knn_fit <- train(as.factor(Made.Donation.in.March.2007) ~ Months.since.Last.Donation + Number.of.Donations + Total.Volume.Donated..c.c.. + Months.since.First.Donation,
data = train,
method = "knn",
metric = "ROC",
trControl = knn_control,
tuneGrid = knn_grid)
knn_fit
# Create training controls for repeated cross-validation for KNN
knn_control <- trainControl(method = "repeatedcv",
number = 10,
classProbs = TRUE,
summaryFunction = LogLossSummary)
# Create vector of hyper-parameter values to tune over
knn_grid <- expand.grid(k = c(1:20))
# Train KNN model
knn_fit <- train(as.factor(Made.Donation.in.March.2007) ~ Months.since.Last.Donation + Number.of.Donations + Total.Volume.Donated..c.c.. + Months.since.First.Donation,
data = train,
method = "knn",
metric = "LogLoss",
trControl = knn_control,
tuneGrid = knn_grid)
# Code borrowed from https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/13064#69102
LogLossSummary <- function (data, lev = NULL, model = NULL) {
LogLoss <- function(actual, pred, eps = 1e-15) {
stopifnot(all(dim(actual) == dim(pred)))
pred[pred < eps] <- eps
pred[pred > 1 - eps] <- 1 - eps
-sum(actual * log(pred)) / nrow(pred)}
if (is.character(data$obs)) data$obs <- factor(data$obs, levels = lev)
pred <- data[, "pred"]
obs <- data[, "obs"]
isNA <- is.na(pred)
pred <- pred[!isNA]
obs <- obs[!isNA]
data <- data[!isNA, ]
cls <- levels(obs)
if (length(obs) + length(pred) == 0) {out <- rep(NA, 2)}
else {
pred <- factor(pred, levels = levels(obs))
out <- unlist(e1071::classAgreement(table(obs, pred)))[c("diag", "kappa")]
probs <- data[, cls]
actual <- model.matrix(~ obs - 1)
out2 <- LogLoss(actual = actual, pred = probs)
}
out <- c(out, out2)
names(out) <- c("Accuracy", "Kappa", "LogLoss")
if (any(is.nan(out))) out[is.nan(out)] <- NA
out
}
# Create training controls for repeated cross-validation for KNN
knn_control <- trainControl(method = "repeatedcv",
number = 10,
classProbs = TRUE,
summaryFunction = LogLossSummary)
# Create vector of hyper-parameter values to tune over
knn_grid <- expand.grid(k = c(1:20))
# Train KNN model
knn_fit <- train(as.factor(Made.Donation.in.March.2007) ~ Months.since.Last.Donation + Number.of.Donations + Total.Volume.Donated..c.c.. + Months.since.First.Donation,
data = train,
method = "knn",
metric = "LogLoss",
trControl = knn_control,
tuneGrid = knn_grid)
knn_fit
# Create training controls for repeated cross-validation for KNN
knn_control <- trainControl(method = "repeatedcv",
number = 10,
classProbs = TRUE,
summaryFunction = LogLossSummary)
# Create vector of hyper-parameter values to tune over
knn_grid <- expand.grid(k = c(1:40))
# Train KNN model
knn_fit <- train(as.factor(Made.Donation.in.March.2007) ~ Months.since.Last.Donation + Number.of.Donations + Total.Volume.Donated..c.c.. + Months.since.First.Donation,
data = train,
method = "knn",
metric = "LogLoss",
trControl = knn_control,
tuneGrid = knn_grid)
knn_fit
# Create training controls for repeated cross-validation for KNN
knn_control <- trainControl(method = "repeatedcv",
number = 10,
classProbs = TRUE,
summaryFunction = LogLossSummary)
# Create vector of hyper-parameter values to tune over
knn_grid <- expand.grid(k = c(1:40))
# Train KNN model
knn_fit <- train(as.factor(Made.Donation.in.March.2007) ~ Months.since.Last.Donation + Number.of.Donations + Total.Volume.Donated..c.c.. + Months.since.First.Donation,
data = train,
method = "knn",
metric = "LogLoss",
maximize = FALSE,
trControl = knn_control,
tuneGrid = knn_grid)
knn_fit
# Create training controls for repeated cross-validation for KNN
knn_control <- trainControl(method = "repeatedcv",
number = 10,
classProbs = TRUE,
summaryFunction = LogLossSummary)
# Create vector of hyper-parameter values to tune over
knn_grid <- expand.grid(k = c(1:100))
# Train KNN model
knn_fit <- train(as.factor(Made.Donation.in.March.2007) ~ Months.since.Last.Donation + Number.of.Donations + Total.Volume.Donated..c.c.. + Months.since.First.Donation,
data = train,
method = "knn",
metric = "LogLoss",
maximize = FALSE,
trControl = knn_control,
tuneGrid = knn_grid)
knn_fit
# Create training controls for repeated cross-validation for KNN
knn_control <- trainControl(method = "repeatedcv",
number = 10,
classProbs = TRUE,
summaryFunction = LogLossSummary)
# Create vector of hyper-parameter values to tune over
knn_grid <- expand.grid(k = c(1:200))
# Train KNN model
knn_fit <- train(as.factor(Made.Donation.in.March.2007) ~ Months.since.Last.Donation + Number.of.Donations + Total.Volume.Donated..c.c.. + Months.since.First.Donation,
data = train,
method = "knn",
metric = "LogLoss",
maximize = FALSE,
trControl = knn_control,
tuneGrid = knn_grid)
knn_fit
# Set seed for reproducibility
set.seed(123)
# Create training controls for repeated cross-validation for KNN
knn_control <- trainControl(method = "repeatedcv",
number = 10,
classProbs = TRUE,
summaryFunction = LogLossSummary)
# Create vector of hyper-parameter values to tune over
knn_grid <- expand.grid(k = seq(1,200,5))
# Train KNN model
knn_fit <- train(as.factor(Made.Donation.in.March.2007) ~ Months.since.Last.Donation + Number.of.Donations + Total.Volume.Donated..c.c.. + Months.since.First.Donation,
data = train,
method = "knn",
metric = "LogLoss",
maximize = FALSE,
trControl = knn_control,
tuneGrid = knn_grid)
knn_fit
# Set seed for reproducibility
set.seed(123)
# Create training controls for repeated cross-validation for KNN
knn_control <- trainControl(method = "repeatedcv",
number = 10,
classProbs = TRUE,
summaryFunction = LogLossSummary)
# Create vector of hyper-parameter values to tune over
knn_grid <- expand.grid(k = seq(1,200,4))
# Train KNN model
knn_fit <- train(as.factor(Made.Donation.in.March.2007) ~ Months.since.Last.Donation + Number.of.Donations + Total.Volume.Donated..c.c.. + Months.since.First.Donation,
data = train,
method = "knn",
metric = "LogLoss",
maximize = FALSE,
trControl = knn_control,
tuneGrid = knn_grid)
knn_fit
plot(knn_fit$results$LogLoss)
# Set seed for reproducibility
set.seed(123)
# Create training controls for repeated cross-validation for KNN
knn_control <- trainControl(method = "repeatedcv",
number = 10,
classProbs = TRUE,
summaryFunction = LogLossSummary)
# Create vector of hyper-parameter values to tune over
knn_grid <- expand.grid(k = c(1:20))
# Train KNN model
knn_fit <- train(as.factor(Made.Donation.in.March.2007) ~ Months.since.Last.Donation + Number.of.Donations + Total.Volume.Donated..c.c.. + Months.since.First.Donation,
data = train,
method = "knn",
metric = "LogLoss",
maximize = FALSE,
trControl = knn_control,
tuneGrid = knn_grid)
knn_fit
plot(knn_fit$results$LogLoss)
knn_pred <- predict(knn_fit, train, type = "prob")
View(knn_pred)
View(example_submission)
knn_pred <- predict(knn_fit, test, type = "prob")
View(knn_pred)
View(test)
knn_submission <- data.frame(X = test$X, Made.Donation.in.March.2007 = knn_pred$yes)
View(knn_submission)
setwd("~/R_projects/predicting_blood_donations/")
knn_submission <- data.frame(X = test$X, Made.Donation.in.March.2007 = knn_pred$yes)
knn_fit$bestTune
write.csv(knn_submission, "knn_submission_14.csv")
knn_submission <- data.frame(Made.Donation.in.March.2007 = knn_pred$yes)
View(knn_submission)
rownames(knn_submission) <- test$X
knn_submission <- data.frame(X = test$X, Made.Donation.in.March.2007 = knn_pred$yes)
write.csv(knn_submission, "knn_submission_14.csv", row.names = FALSE)
knn_submission <- data.frame(test$X, Made.Donation.in.March.2007 = knn_pred$yes)
knn_submission <- data.frame(test$X, Made.Donation.in.March.2007 = knn_pred$yes)
colnames(knn_submission)[1] <- ""
# Write CSV to submit
write.csv(knn_submission, "knn_submission_14.csv", row.names = FALSE)
knn_submission <- data.frame(test$X, knn_pred$yes)
colnames(knn_submission)[2] <- "Made Donation in March 2007"
# Create data frame to submit
knn_submission <- data.frame(test$X, knn_pred$yes)
colnames(knn_submission) <- c("", "Made Donation in March 2007")
# Write CSV to submit
write.csv(knn_submission, "knn_submission_14.csv", row.names = FALSE)
# Set seed for reproducibility
set.seed(123)
# Create training controls for repeated cross-validation for Elastic Net
elnet_control <- trainControl(method = "repeatedcv",
number = 10,
classProbs = TRUE,
summaryFunction = LogLossSummary)
# Create grid of hyper-parameter values to tune over
elnet_grid <- expand.grid(alpha = seq(0.05,0.95,0.05),
lambda = 10^seq(-1,-4,length=50))
elnet_fit <- train(as.factor(Made.Donation.in.March.2007) ~ Months.since.Last.Donation + Number.of.Donations + Total.Volume.Donated..c.c.. + Months.since.First.Donation,
data = train,
method = "glmnet",
metric = "LogLoss",
maximize = FALSE,
trControl = elnet_control,
tuneGrid = elnet_grid)
# Set seed for reproducibility
set.seed(123)
# Create training controls for repeated cross-validation for Elastic Net
elnet_control <- trainControl(method = "repeatedcv",
number = 10,
classProbs = TRUE,
summaryFunction = LogLossSummary)
# Create grid of hyper-parameter values to tune over
elnet_grid <- expand.grid(alpha = seq(0,1,0.05),
lambda = 10^seq(-1,-4,length=50))
# Train KNN model
elnet_fit <- train(as.factor(Made.Donation.in.March.2007) ~ Months.since.Last.Donation + Number.of.Donations + Total.Volume.Donated..c.c.. + Months.since.First.Donation,
data = train,
method = "glmnet",
metric = "LogLoss",
maximize = FALSE,
trControl = elnet_control,
tuneGrid = elnet_grid)
elnet_pred <- predict(elnet_fit, test, type = "prob")
View(elnet_pred)
elnet_submission <- data.frame(test$X, elnet_pred$yes)
colnames(elnet_submission) <- c("", "Made Donation in March 2007")
elnet_fit
elnet_submission <- data.frame(test$X, elnet_pred$yes)
colnames(elnet_submission) <- c("", "Made Donation in March 2007")
write.csv(elnet_submission, "elnet_submission_14.csv", row.names = FALSE)
write.csv(elnet_submission, "elnet_submission.csv", row.names = FALSE)
View(elnet_submission)
# Set seed for reproducibility
set.seed(123)
# Create training controls for K-Fold cross-validation for Elastic Net
svm_control <- trainControl(method = "cv",
number = 10,
classProbs = TRUE,
summaryFunction = LogLossSummary)
# Train SVM model with Linear Kernel
svm_fit <- train(as.factor(Made.Donation.in.March.2007) ~ Months.since.Last.Donation + Number.of.Donations + Total.Volume.Donated..c.c.. + Months.since.First.Donation,
data = train,
method = "svmLinear",
# We can add options to pre-process the data
preProc = c("center", "scale"),
metric = "LogLoss",
maximize = FALSE,
trControl = svm_control)
svm_fit
seq(2^-5,2^3)
seq(2^-7,2^3)
2^seq(-7,3)
2^seq(-10,5)
2^seq(-10,10)
svm_grid <- expand.grid(C = 2^seq(-10,10))
# Set seed for reproducibility
set.seed(123)
# Create training controls for K-Fold cross-validation for Elastic Net
svm_control <- trainControl(method = "cv",
number = 10,
classProbs = TRUE,
summaryFunction = LogLossSummary)
# Create grid of hyper-parameter values to tune over
svm_grid <- expand.grid(C = 2^seq(-10,10))
# Train SVM model with Linear Kernel
svm_fit <- train(as.factor(Made.Donation.in.March.2007) ~ Months.since.Last.Donation + Number.of.Donations + Total.Volume.Donated..c.c.. + Months.since.First.Donation,
data = train,
method = "svmLinear",
# We can add options to pre-process the data
preProc = c("center", "scale"),
metric = "LogLoss",
maximize = FALSE,
trControl = svm_control,
tuneGrid = svm_grid)
# Set seed for reproducibility
set.seed(123)
# Create training controls for repeated cross-validation for Elastic Net
elnet_control <- trainControl(method = "repeatedcv",
number = 10,
classProbs = TRUE,
summaryFunction = LogLossSummary)
# Create grid of hyper-parameter values to tune over
elnet_grid <- expand.grid(alpha = seq(0,1,0.05),
lambda = 10^seq(-1,-4,length=20))
# Train Elastic Net model
elnet_fit <- train(as.factor(Made.Donation.in.March.2007) ~ Months.since.Last.Donation + Number.of.Donations + Total.Volume.Donated..c.c.. + Months.since.First.Donation,
data = train,
method = "glmnet",
metric = "LogLoss",
maximize = FALSE,
trControl = elnet_control,
tuneGrid = elnet_grid)
# Predict on test data to output class probabilities
elnet_pred <- predict(elnet_fit, test, type = "prob")
# Create data frame to submit
elnet_submission <- data.frame(test$X, elnet_pred$yes)
colnames(elnet_submission) <- c("", "Made Donation in March 2007")
# Write CSV to submit
write.csv(elnet_submission, "elnet_submission.csv", row.names = FALSE)
# Set seed for reproducibility
set.seed(123)
# Create training controls for K-Fold cross-validation for Elastic Net
svm_control <- trainControl(method = "cv",
number = 10,
classProbs = TRUE,
summaryFunction = LogLossSummary)
# Create grid of hyper-parameter values to tune over
svm_grid <- expand.grid(C = 2^seq(-5,5))
# Train SVM model with Linear Kernel
svm_fit <- train(as.factor(Made.Donation.in.March.2007) ~ Months.since.Last.Donation + Number.of.Donations + Total.Volume.Donated..c.c.. + Months.since.First.Donation,
data = train,
method = "svmLinear",
# We can add options to pre-process the data
preProc = c("center", "scale"),
metric = "LogLoss",
maximize = FALSE,
trControl = svm_control,
tuneGrid = svm_grid)
# Predict on test data to output class probabilities
svm_pred <- predict(svm_fit, test, type = "prob")
# Create data frame to submit
svm_submission <- data.frame(test$X, svm_pred$yes)
colnames(svm_submission) <- c("", "Made Donation in March 2007")
# Write CSV to submit
write.csv(svm_submission, "svm_submission.csv", row.names = FALSE)
# Set seed for reproducibility
set.seed(123)
# Create training controls for repeated cross-validation for Elastic Net
elnet_control <- trainControl(method = "repeatedcv",
number = 10,
classProbs = TRUE,
summaryFunction = LogLossSummary)
# Create grid of hyper-parameter values to tune over
elnet_grid <- expand.grid(alpha = seq(0,1,0.05),
lambda = 10^seq(-1,-4,length=20))
# Train Elastic Net model
elnet_fit <- train(as.factor(Made.Donation.in.March.2007) ~ Months.since.Last.Donation + Number.of.Donations + Total.Volume.Donated..c.c.. + Months.since.First.Donation,
data = train,
method = "glmnet",
metric = "LogLoss",
maximize = FALSE,
trControl = elnet_control,
tuneGrid = elnet_grid)
# Predict on test data to output class probabilities
elnet_pred <- predict(elnet_fit, test, type = "prob")
# Create data frame to submit
elnet_submission <- data.frame(test$X, elnet_pred$yes)
colnames(elnet_submission) <- c("", "Made Donation in March 2007")
# Write CSV to submit
write.csv(elnet_submission, "elnet_submission.csv", row.names = FALSE)
svm_fit
